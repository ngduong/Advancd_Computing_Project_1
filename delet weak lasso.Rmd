---
title: "delete weak"
author: 'Crystal Li' 
output: html_document
---

```{r setup, echo = FALSE}
library(tidyverse)
library(MASS)
library(matrixcalc)
library(pracma)
library(glmnet)
library(dplyr)
library(patchwork)
library(ggplot2)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


# Generate data


Default of correlation is set to be 0.3, maybe it should be other number like 0.5.

Default of coef_strong is 5.

X follows N(0,1).

```{r}
sim_beta_strong = function(n_strong, coef_strong){
  rep(coef_strong, n_strong) + runif(n_strong, min = 0, max = coef_strong)
}


sim_data = function(n_sample = 200, n_parameter = 50, prop_strong = 0.1, prop_wbc = 0.2, prop_wai = 0.2, c = 1, cor = 0.3, coef_strong = 5) {
  # Numbers of four signals
  n_strong = as.integer(n_parameter * prop_strong) # strong
  n_wbc = as.integer(n_parameter * prop_wbc) # weak but correlated
  n_wai = as.integer(n_parameter * prop_wai) # weak and independent
  n_null = n_parameter - n_strong - n_wbc - n_wai # null
  
  if (n_null < 0) {
    return("Given parameters' proportions are not valid.")
  }
  
  bound = c * sqrt(log(n_parameter) / n_sample) # threshold of weak/strong, the default is 0.14
  if (coef_strong < bound) {
    coef_strong = coef_strong + 2 * bound
  }
  
  cor_matrix = diag(n_parameter)
  
  # add correlation
  for (i in 1:n_strong) {
    cor_matrix[i, (n_strong + n_wai + i)] = cor
    cor_matrix[i, (n_strong + n_wai + n_wbc + 1 - i)] = cor
    cor_matrix[(n_strong + n_wai + i), i] = cor
    cor_matrix[(n_strong + n_wai + n_wbc + 1 - i), i] = cor
  }
  
  
  if (!is.positive.definite(cor_matrix)) {
    return("The correlation matrix is not valid.")
  }
  
  # simulate the data from multivariate normal
  X = mvrnorm(n = n_sample, mu = rep(0, n_parameter), Sigma = cor_matrix) # var = 1, correlation = covariance
  
  beta = c(
    sim_beta_strong(n_strong, coef_strong),
    runif(min = bound/2, max = bound, n = n_wai), 
    runif(min = bound/2, max = bound, n = n_wbc),
    rep(0, n_null) 
  )
  
  Y = 1 + X %*% beta + rnorm(n_sample)
  data = as_tibble(data.frame(cbind(X, Y)))
  
  # Name the columns
  cols = c(
    str_c("strong", 1:n_strong, sep = "_"),
    str_c("wai", 1:n_wai, sep = "_"),
    str_c("wbc", 1:n_wbc, sep = "_"),
    str_c("null", 1:n_null, sep = "_"),
    "Y"
   )
   colnames(data) = cols
   data = data %>% 
     dplyr::select(Y, everything())

  list(beta = beta, 
       correlation = cor,
       n_parameter = n_parameter,
       prop_strong = prop_strong,
       prop_wbc = prop_wbc, 
       prop_wai = prop_wbc,
       n_strong = n_strong,
       n_wai = n_wai,
       n_wbc = n_wbc,
       data = data
       )
}
```


# Vary the amount of n_parameter 10, 20, ..., 100 for prop_strong = 0.1, prop_wbc = 0.2, prop_wai = 0.2, 100 samples for each, and we vary corr values 0.3, 0.5, 0.7

```{r}
data_delete = vector("list", length = 100)
    for (j in 1:100) {
  data_delete[[j]] =  sim_data(n_parameter = 50, cor = 0.3)
}
```

```{r}
#get the coef of strong signals for the "true"
true_coef = vector("list", length = 100)
for (j in 1:100){
  coef= data_delete[[j]][[1]]
  strong = coef[1:5]
  true_coef[[j]] = strong
}
```

```{r}
#delete weak signlas before fitting the models and construct a new list of datasets
data_new = vector("list")

for (i in 1:100){
  output = vector("list")
  
  for (j in 1:20){
    data = data_delete[[i]][[10]] 
    output[[j]] = data[-c(7:(6+j))]
  }
  data_new[[i]] = output
}
```

```{r}
#fit the LASSO models using new deleted datasets
#and store the new fitted param in a ne list
param_new = vector("list", length = 100)
for (i in 1:100) {
  output_para = vector("list", length = 20)
  for (j in 1:20) {
    data = data_new[[i]][[j]]
    X = data%>% 
    dplyr::select(-Y) %>% 
    as.matrix()
    Y= data$Y
    # 10-fold CV using mean squared error
    fit.lasso <- cv.glmnet(X, Y, nfolds = 10,type.measure = "mse") 
    # one standard-error rule
    param.best <- fit.lasso$glmnet.fit$beta[, fit.lasso$lambda==fit.lasso$lambda.1se]
    output_para[[j]] = param.best[param.best != 0]

  param_new[[i]] = output_para
  }}

```

```{r}
# extract the fitted new strong signals' coeff in a list
fitted_coef = vector('list', length = 20)
for (i in 1:100){
  output_coef2 = vector('list', length = 20)
  for (j in 1:20){
    p = unlist(param_new[[i]][j]) 
    pnames2 = strsplit(names(p), split = '_')
    for (n in 1:length(p)){
      names(p)[n] = pnames2[[n]][1]
    }
    output_coef2[[j]] = p[names(p)=='strong']
  }
  fitted_coef[[i]] = output_coef2
}
```

```{r}
#calculate the MSE for each group
mse_df_lasso = data.frame(matrix (ncol = 0, nrow = 100))
for (i in 1:100){
  mse_list = data.frame(matrix (ncol = 0, nrow = 20))
  for (j in 1:20){
    mse_col = as.vector(mean(true_coef[[i]]-fitted_coef[[i]][[j]])^2)
    mse_list = cbind(mse_list,mse_col)
    names(mse_list)[j] = j
  }
  mse_df_lasso =cbind(mse_df_lasso,mse_list)
}

bias_df_lasso = data.frame(matrix (ncol = 0, nrow = 100))
for (i in 1:100){
  bias_list = data.frame(matrix (ncol = 0, nrow = 20))
  for (j in 1:20){
    bias_col = as.vector(true_coef[[i]]-fitted_coef[[i]][[j]])
    bias_list = cbind(bias_list,bias_col)
    names(bias_list)[j] = j
  }
  bias_df_lasso =cbind(bias_df_lasso,bias_list)
}
```

Visualize MSE for the Lasso
```{r}
mse_df_lasso_test = mse_df_lasso %>% 
  pivot_longer(
    everything(),
    names_to = "n_missing",
    values_to = "mse") %>% 
  dplyr::select(mse, n_missing) %>% 
  mutate(n_missing = as.numeric(n_missing)) %>% 
  group_by(n_missing) %>% 
  summarise(mean = mean(mse)) %>% 
  mutate(measure = "mse") 

bias_df_lasso_test = bias_df_lasso %>% 
  pivot_longer(
    everything(),
    names_to = "n_missing",
    values_to = "bias") %>% 
  dplyr::select(bias, n_missing) %>% 
  mutate(n_missing = as.numeric(n_missing)) %>% 
  group_by(n_missing) %>% 
  summarise(mean = mean(bias)) %>% 
  mutate(measure = "bias") 

lasso_task2_data = rbind(mse_df_lasso_test, bias_df_lasso_test) %>% mutate(type = "LASSO")
```

lasso_task2_data %>% 
  ggplot(aes(x = n_missing, y = mean, group = measure))+
  geom_point(aes(linetype = measure), alpha = 0.3)+
  geom_smooth(aes(linetype = measure),se = T, method = "loess",stat = "smooth", formula = y~x)
   labs(title = "Mean of MSE of strong signals against Number of missing weak signals",
       x = "Number of missing weak signals",
       y = "Mean of MSE of strong signals") +  
   theme_bw()
